{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import whatever will be used in this notebook\n",
    "import pylab\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import SMOTE to balance trainset \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Import from sklearn\n",
    "#Estimators:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Set generation \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Performance metrics:\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#K-fold crossvalidation\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surpress warnings regarding the version of the pandas library which is used \n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make variable for the imported models\n",
    "modelSVC = SVC()\n",
    "modelRF = RandomForestClassifier()\n",
    "modelLR = LogisticRegression()\n",
    "modelKNN = KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the csv file and remove the extra ID column\n",
    "credit = pd.read_csv(\"C:\\\\Users\\\\Jeroen\\\\Desktop\\\\Ubiqum\\\\Data Science\\\\Excel Files\\\\credit_3.csv\", header = 0)\n",
    "credit = credit[credit.columns[1:len(credit.columns)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAYSTAT_SEP</th>\n",
       "      <th>CUR_BIL_SEP</th>\n",
       "      <th>PAID_SEP</th>\n",
       "      <th>CREDIT</th>\n",
       "      <th>CREDIT_RATIO</th>\n",
       "      <th>AGE</th>\n",
       "      <th>No_payment</th>\n",
       "      <th>Paid_in_time</th>\n",
       "      <th>Paid_partly</th>\n",
       "      <th>1_month_late</th>\n",
       "      <th>2_months_late</th>\n",
       "      <th>3_months_late</th>\n",
       "      <th>4_months_late</th>\n",
       "      <th>5_months_late</th>\n",
       "      <th>6_months_late</th>\n",
       "      <th>7_months_late</th>\n",
       "      <th>8_months_late</th>\n",
       "      <th>DEFAULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29461</th>\n",
       "      <td>0.017741</td>\n",
       "      <td>1.849291</td>\n",
       "      <td>0.164656</td>\n",
       "      <td>0.412625</td>\n",
       "      <td>1.132625</td>\n",
       "      <td>0.387036</td>\n",
       "      <td>-0.31168</td>\n",
       "      <td>-0.488987</td>\n",
       "      <td>0.999729</td>\n",
       "      <td>-0.355373</td>\n",
       "      <td>-0.315466</td>\n",
       "      <td>-0.105112</td>\n",
       "      <td>-0.050852</td>\n",
       "      <td>-0.029718</td>\n",
       "      <td>-0.019325</td>\n",
       "      <td>-0.017479</td>\n",
       "      <td>-0.025401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29462</th>\n",
       "      <td>-0.875875</td>\n",
       "      <td>-0.682263</td>\n",
       "      <td>-0.234720</td>\n",
       "      <td>-0.127385</td>\n",
       "      <td>-1.004498</td>\n",
       "      <td>0.822032</td>\n",
       "      <td>-0.31168</td>\n",
       "      <td>2.045043</td>\n",
       "      <td>-1.000272</td>\n",
       "      <td>-0.355373</td>\n",
       "      <td>-0.315466</td>\n",
       "      <td>-0.105112</td>\n",
       "      <td>-0.050852</td>\n",
       "      <td>-0.029718</td>\n",
       "      <td>-0.019325</td>\n",
       "      <td>-0.017479</td>\n",
       "      <td>-0.025401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29463</th>\n",
       "      <td>3.592206</td>\n",
       "      <td>-0.656821</td>\n",
       "      <td>-0.344828</td>\n",
       "      <td>-1.053118</td>\n",
       "      <td>-0.758007</td>\n",
       "      <td>0.169538</td>\n",
       "      <td>-0.31168</td>\n",
       "      <td>-0.488987</td>\n",
       "      <td>-1.000272</td>\n",
       "      <td>-0.355373</td>\n",
       "      <td>-0.315466</td>\n",
       "      <td>-0.105112</td>\n",
       "      <td>19.664957</td>\n",
       "      <td>-0.029718</td>\n",
       "      <td>-0.019325</td>\n",
       "      <td>-0.017479</td>\n",
       "      <td>-0.025401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29464</th>\n",
       "      <td>0.911357</td>\n",
       "      <td>-0.727253</td>\n",
       "      <td>4.803964</td>\n",
       "      <td>-0.667396</td>\n",
       "      <td>1.388081</td>\n",
       "      <td>0.604534</td>\n",
       "      <td>-0.31168</td>\n",
       "      <td>-0.488987</td>\n",
       "      <td>-1.000272</td>\n",
       "      <td>2.813944</td>\n",
       "      <td>-0.315466</td>\n",
       "      <td>-0.105112</td>\n",
       "      <td>-0.050852</td>\n",
       "      <td>-0.029718</td>\n",
       "      <td>-0.019325</td>\n",
       "      <td>-0.017479</td>\n",
       "      <td>-0.025401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29465</th>\n",
       "      <td>0.017741</td>\n",
       "      <td>-0.057084</td>\n",
       "      <td>-0.220274</td>\n",
       "      <td>-0.898829</td>\n",
       "      <td>1.384032</td>\n",
       "      <td>1.148279</td>\n",
       "      <td>-0.31168</td>\n",
       "      <td>-0.488987</td>\n",
       "      <td>0.999729</td>\n",
       "      <td>-0.355373</td>\n",
       "      <td>-0.315466</td>\n",
       "      <td>-0.105112</td>\n",
       "      <td>-0.050852</td>\n",
       "      <td>-0.029718</td>\n",
       "      <td>-0.019325</td>\n",
       "      <td>-0.017479</td>\n",
       "      <td>-0.025401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PAYSTAT_SEP  CUR_BIL_SEP  PAID_SEP    CREDIT  CREDIT_RATIO       AGE  \\\n",
       "29461     0.017741     1.849291  0.164656  0.412625      1.132625  0.387036   \n",
       "29462    -0.875875    -0.682263 -0.234720 -0.127385     -1.004498  0.822032   \n",
       "29463     3.592206    -0.656821 -0.344828 -1.053118     -0.758007  0.169538   \n",
       "29464     0.911357    -0.727253  4.803964 -0.667396      1.388081  0.604534   \n",
       "29465     0.017741    -0.057084 -0.220274 -0.898829      1.384032  1.148279   \n",
       "\n",
       "       No_payment  Paid_in_time  Paid_partly  1_month_late  2_months_late  \\\n",
       "29461    -0.31168     -0.488987     0.999729     -0.355373      -0.315466   \n",
       "29462    -0.31168      2.045043    -1.000272     -0.355373      -0.315466   \n",
       "29463    -0.31168     -0.488987    -1.000272     -0.355373      -0.315466   \n",
       "29464    -0.31168     -0.488987    -1.000272      2.813944      -0.315466   \n",
       "29465    -0.31168     -0.488987     0.999729     -0.355373      -0.315466   \n",
       "\n",
       "       3_months_late  4_months_late  5_months_late  6_months_late  \\\n",
       "29461      -0.105112      -0.050852      -0.029718      -0.019325   \n",
       "29462      -0.105112      -0.050852      -0.029718      -0.019325   \n",
       "29463      -0.105112      19.664957      -0.029718      -0.019325   \n",
       "29464      -0.105112      -0.050852      -0.029718      -0.019325   \n",
       "29465      -0.105112      -0.050852      -0.029718      -0.019325   \n",
       "\n",
       "       7_months_late  8_months_late  DEFAULT  \n",
       "29461      -0.017479      -0.025401        1  \n",
       "29462      -0.017479      -0.025401        1  \n",
       "29463      -0.017479      -0.025401        0  \n",
       "29464      -0.017479      -0.025401        0  \n",
       "29465      -0.017479      -0.025401        0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Give head of the df so it is easily visible which vars should function as independent variable\n",
    "credit.head()\n",
    "credit.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAYSTAT_SEP</th>\n",
       "      <th>CUR_BIL_SEP</th>\n",
       "      <th>PAID_SEP</th>\n",
       "      <th>CREDIT</th>\n",
       "      <th>CREDIT_RATIO</th>\n",
       "      <th>AGE</th>\n",
       "      <th>No_payment</th>\n",
       "      <th>Paid_in_time</th>\n",
       "      <th>Paid_partly</th>\n",
       "      <th>1_month_late</th>\n",
       "      <th>2_months_late</th>\n",
       "      <th>3_months_late</th>\n",
       "      <th>4_months_late</th>\n",
       "      <th>5_months_late</th>\n",
       "      <th>6_months_late</th>\n",
       "      <th>7_months_late</th>\n",
       "      <th>8_months_late</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.804974</td>\n",
       "      <td>-0.652117</td>\n",
       "      <td>-0.344828</td>\n",
       "      <td>-1.130262</td>\n",
       "      <td>-0.651099</td>\n",
       "      <td>-1.244199</td>\n",
       "      <td>-0.31168</td>\n",
       "      <td>-0.488987</td>\n",
       "      <td>-1.000272</td>\n",
       "      <td>-0.355373</td>\n",
       "      <td>3.169916</td>\n",
       "      <td>-0.105112</td>\n",
       "      <td>-0.050852</td>\n",
       "      <td>-0.029718</td>\n",
       "      <td>-0.019325</td>\n",
       "      <td>-0.017479</td>\n",
       "      <td>-0.025401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.875875</td>\n",
       "      <td>-0.668758</td>\n",
       "      <td>-0.344828</td>\n",
       "      <td>-0.358818</td>\n",
       "      <td>-0.999086</td>\n",
       "      <td>-1.026701</td>\n",
       "      <td>-0.31168</td>\n",
       "      <td>2.045043</td>\n",
       "      <td>-1.000272</td>\n",
       "      <td>-0.355373</td>\n",
       "      <td>-0.315466</td>\n",
       "      <td>-0.105112</td>\n",
       "      <td>-0.050852</td>\n",
       "      <td>-0.029718</td>\n",
       "      <td>-0.019325</td>\n",
       "      <td>-0.017479</td>\n",
       "      <td>-0.025401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017741</td>\n",
       "      <td>-0.309746</td>\n",
       "      <td>-0.253840</td>\n",
       "      <td>-0.590251</td>\n",
       "      <td>-0.649230</td>\n",
       "      <td>-0.156709</td>\n",
       "      <td>-0.31168</td>\n",
       "      <td>-0.488987</td>\n",
       "      <td>0.999729</td>\n",
       "      <td>-0.355373</td>\n",
       "      <td>-0.315466</td>\n",
       "      <td>-0.105112</td>\n",
       "      <td>-0.050852</td>\n",
       "      <td>-0.029718</td>\n",
       "      <td>-0.019325</td>\n",
       "      <td>-0.017479</td>\n",
       "      <td>-0.025401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017741</td>\n",
       "      <td>-0.069778</td>\n",
       "      <td>-0.224950</td>\n",
       "      <td>-0.898829</td>\n",
       "      <td>1.350797</td>\n",
       "      <td>0.169538</td>\n",
       "      <td>-0.31168</td>\n",
       "      <td>-0.488987</td>\n",
       "      <td>0.999729</td>\n",
       "      <td>-0.355373</td>\n",
       "      <td>-0.315466</td>\n",
       "      <td>-0.105112</td>\n",
       "      <td>-0.050852</td>\n",
       "      <td>-0.029718</td>\n",
       "      <td>-0.019325</td>\n",
       "      <td>-0.017479</td>\n",
       "      <td>-0.025401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.875875</td>\n",
       "      <td>-0.588526</td>\n",
       "      <td>-0.224950</td>\n",
       "      <td>-0.898829</td>\n",
       "      <td>-0.754215</td>\n",
       "      <td>2.344518</td>\n",
       "      <td>-0.31168</td>\n",
       "      <td>2.045043</td>\n",
       "      <td>-1.000272</td>\n",
       "      <td>-0.355373</td>\n",
       "      <td>-0.315466</td>\n",
       "      <td>-0.105112</td>\n",
       "      <td>-0.050852</td>\n",
       "      <td>-0.029718</td>\n",
       "      <td>-0.019325</td>\n",
       "      <td>-0.017479</td>\n",
       "      <td>-0.025401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PAYSTAT_SEP  CUR_BIL_SEP  PAID_SEP    CREDIT  CREDIT_RATIO       AGE  \\\n",
       "0     1.804974    -0.652117 -0.344828 -1.130262     -0.651099 -1.244199   \n",
       "1    -0.875875    -0.668758 -0.344828 -0.358818     -0.999086 -1.026701   \n",
       "2     0.017741    -0.309746 -0.253840 -0.590251     -0.649230 -0.156709   \n",
       "3     0.017741    -0.069778 -0.224950 -0.898829      1.350797  0.169538   \n",
       "4    -0.875875    -0.588526 -0.224950 -0.898829     -0.754215  2.344518   \n",
       "\n",
       "   No_payment  Paid_in_time  Paid_partly  1_month_late  2_months_late  \\\n",
       "0    -0.31168     -0.488987    -1.000272     -0.355373       3.169916   \n",
       "1    -0.31168      2.045043    -1.000272     -0.355373      -0.315466   \n",
       "2    -0.31168     -0.488987     0.999729     -0.355373      -0.315466   \n",
       "3    -0.31168     -0.488987     0.999729     -0.355373      -0.315466   \n",
       "4    -0.31168      2.045043    -1.000272     -0.355373      -0.315466   \n",
       "\n",
       "   3_months_late  4_months_late  5_months_late  6_months_late  7_months_late  \\\n",
       "0      -0.105112      -0.050852      -0.029718      -0.019325      -0.017479   \n",
       "1      -0.105112      -0.050852      -0.029718      -0.019325      -0.017479   \n",
       "2      -0.105112      -0.050852      -0.029718      -0.019325      -0.017479   \n",
       "3      -0.105112      -0.050852      -0.029718      -0.019325      -0.017479   \n",
       "4      -0.105112      -0.050852      -0.029718      -0.019325      -0.017479   \n",
       "\n",
       "   8_months_late  \n",
       "0      -0.025401  \n",
       "1      -0.025401  \n",
       "2      -0.025401  \n",
       "3      -0.025401  \n",
       "4      -0.025401  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select the features that will function as independent variables:\n",
    "credit_indep = credit.iloc[:, 0:(len(credit.columns)-1)]\n",
    "credit_indep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: DEFAULT, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select the dependent variable and turn it into a seperate vector:\n",
    "credit_dep = credit['DEFAULT']\n",
    "credit_dep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAYSTAT_SEP</th>\n",
       "      <th>CUR_BIL_SEP</th>\n",
       "      <th>PAID_SEP</th>\n",
       "      <th>CREDIT</th>\n",
       "      <th>CREDIT_RATIO</th>\n",
       "      <th>AGE</th>\n",
       "      <th>No_payment</th>\n",
       "      <th>Paid_in_time</th>\n",
       "      <th>Paid_partly</th>\n",
       "      <th>1_month_late</th>\n",
       "      <th>2_months_late</th>\n",
       "      <th>3_months_late</th>\n",
       "      <th>4_months_late</th>\n",
       "      <th>5_months_late</th>\n",
       "      <th>6_months_late</th>\n",
       "      <th>7_months_late</th>\n",
       "      <th>8_months_late</th>\n",
       "      <th>DEFAULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>29466.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.208420e-15</td>\n",
       "      <td>-2.103345e-16</td>\n",
       "      <td>2.656975e-16</td>\n",
       "      <td>-3.281235e-15</td>\n",
       "      <td>3.921537e-16</td>\n",
       "      <td>4.803280e-16</td>\n",
       "      <td>1.062419e-14</td>\n",
       "      <td>2.150282e-15</td>\n",
       "      <td>1.553156e-15</td>\n",
       "      <td>1.034401e-15</td>\n",
       "      <td>-2.365040e-15</td>\n",
       "      <td>5.959323e-15</td>\n",
       "      <td>-7.981141e-16</td>\n",
       "      <td>-7.367930e-16</td>\n",
       "      <td>-4.664973e-16</td>\n",
       "      <td>-8.970036e-16</td>\n",
       "      <td>-8.155870e-15</td>\n",
       "      <td>0.792914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>0.405225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.769491e+00</td>\n",
       "      <td>-2.943419e+00</td>\n",
       "      <td>-3.448283e-01</td>\n",
       "      <td>-1.207406e+00</td>\n",
       "      <td>-4.485552e+00</td>\n",
       "      <td>-1.570446e+00</td>\n",
       "      <td>-3.116795e-01</td>\n",
       "      <td>-4.889872e-01</td>\n",
       "      <td>-1.000272e+00</td>\n",
       "      <td>-3.553731e-01</td>\n",
       "      <td>-3.154657e-01</td>\n",
       "      <td>-1.051123e-01</td>\n",
       "      <td>-5.085188e-02</td>\n",
       "      <td>-2.971788e-02</td>\n",
       "      <td>-1.932488e-02</td>\n",
       "      <td>-1.747942e-02</td>\n",
       "      <td>-2.540132e-02</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.758749e-01</td>\n",
       "      <td>-6.490855e-01</td>\n",
       "      <td>-2.847691e-01</td>\n",
       "      <td>-8.988289e-01</td>\n",
       "      <td>-9.815463e-01</td>\n",
       "      <td>-8.092031e-01</td>\n",
       "      <td>-3.116795e-01</td>\n",
       "      <td>-4.889872e-01</td>\n",
       "      <td>-1.000272e+00</td>\n",
       "      <td>-3.553731e-01</td>\n",
       "      <td>-3.154657e-01</td>\n",
       "      <td>-1.051123e-01</td>\n",
       "      <td>-5.085188e-02</td>\n",
       "      <td>-2.971788e-02</td>\n",
       "      <td>-1.932488e-02</td>\n",
       "      <td>-1.747942e-02</td>\n",
       "      <td>-2.540132e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.774131e-02</td>\n",
       "      <td>-3.848821e-01</td>\n",
       "      <td>-2.132614e-01</td>\n",
       "      <td>-2.045296e-01</td>\n",
       "      <td>-2.549452e-01</td>\n",
       "      <td>-1.567091e-01</td>\n",
       "      <td>-3.116795e-01</td>\n",
       "      <td>-4.889872e-01</td>\n",
       "      <td>9.997285e-01</td>\n",
       "      <td>-3.553731e-01</td>\n",
       "      <td>-3.154657e-01</td>\n",
       "      <td>-1.051123e-01</td>\n",
       "      <td>-5.085188e-02</td>\n",
       "      <td>-2.971788e-02</td>\n",
       "      <td>-1.932488e-02</td>\n",
       "      <td>-1.747942e-02</td>\n",
       "      <td>-2.540132e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.774131e-02</td>\n",
       "      <td>2.204590e-01</td>\n",
       "      <td>-4.252409e-02</td>\n",
       "      <td>5.669140e-01</td>\n",
       "      <td>9.783657e-01</td>\n",
       "      <td>6.045339e-01</td>\n",
       "      <td>-3.116795e-01</td>\n",
       "      <td>-4.889872e-01</td>\n",
       "      <td>9.997285e-01</td>\n",
       "      <td>-3.553731e-01</td>\n",
       "      <td>-3.154657e-01</td>\n",
       "      <td>-1.051123e-01</td>\n",
       "      <td>-5.085188e-02</td>\n",
       "      <td>-2.971788e-02</td>\n",
       "      <td>-1.932488e-02</td>\n",
       "      <td>-1.747942e-02</td>\n",
       "      <td>-2.540132e-02</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.166671e+00</td>\n",
       "      <td>1.233379e+01</td>\n",
       "      <td>5.201533e+01</td>\n",
       "      <td>6.429886e+00</td>\n",
       "      <td>1.474319e+01</td>\n",
       "      <td>4.736996e+00</td>\n",
       "      <td>3.208424e+00</td>\n",
       "      <td>2.045043e+00</td>\n",
       "      <td>9.997285e-01</td>\n",
       "      <td>2.813944e+00</td>\n",
       "      <td>3.169916e+00</td>\n",
       "      <td>9.513638e+00</td>\n",
       "      <td>1.966496e+01</td>\n",
       "      <td>3.364978e+01</td>\n",
       "      <td>5.174676e+01</td>\n",
       "      <td>5.721014e+01</td>\n",
       "      <td>3.936803e+01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PAYSTAT_SEP   CUR_BIL_SEP      PAID_SEP        CREDIT  CREDIT_RATIO  \\\n",
       "count  2.946600e+04  2.946600e+04  2.946600e+04  2.946600e+04  2.946600e+04   \n",
       "mean  -3.208420e-15 -2.103345e-16  2.656975e-16 -3.281235e-15  3.921537e-16   \n",
       "std    1.000017e+00  1.000017e+00  1.000017e+00  1.000017e+00  1.000017e+00   \n",
       "min   -1.769491e+00 -2.943419e+00 -3.448283e-01 -1.207406e+00 -4.485552e+00   \n",
       "25%   -8.758749e-01 -6.490855e-01 -2.847691e-01 -8.988289e-01 -9.815463e-01   \n",
       "50%    1.774131e-02 -3.848821e-01 -2.132614e-01 -2.045296e-01 -2.549452e-01   \n",
       "75%    1.774131e-02  2.204590e-01 -4.252409e-02  5.669140e-01  9.783657e-01   \n",
       "max    7.166671e+00  1.233379e+01  5.201533e+01  6.429886e+00  1.474319e+01   \n",
       "\n",
       "                AGE    No_payment  Paid_in_time   Paid_partly  1_month_late  \\\n",
       "count  2.946600e+04  2.946600e+04  2.946600e+04  2.946600e+04  2.946600e+04   \n",
       "mean   4.803280e-16  1.062419e-14  2.150282e-15  1.553156e-15  1.034401e-15   \n",
       "std    1.000017e+00  1.000017e+00  1.000017e+00  1.000017e+00  1.000017e+00   \n",
       "min   -1.570446e+00 -3.116795e-01 -4.889872e-01 -1.000272e+00 -3.553731e-01   \n",
       "25%   -8.092031e-01 -3.116795e-01 -4.889872e-01 -1.000272e+00 -3.553731e-01   \n",
       "50%   -1.567091e-01 -3.116795e-01 -4.889872e-01  9.997285e-01 -3.553731e-01   \n",
       "75%    6.045339e-01 -3.116795e-01 -4.889872e-01  9.997285e-01 -3.553731e-01   \n",
       "max    4.736996e+00  3.208424e+00  2.045043e+00  9.997285e-01  2.813944e+00   \n",
       "\n",
       "       2_months_late  3_months_late  4_months_late  5_months_late  \\\n",
       "count   2.946600e+04   2.946600e+04   2.946600e+04   2.946600e+04   \n",
       "mean   -2.365040e-15   5.959323e-15  -7.981141e-16  -7.367930e-16   \n",
       "std     1.000017e+00   1.000017e+00   1.000017e+00   1.000017e+00   \n",
       "min    -3.154657e-01  -1.051123e-01  -5.085188e-02  -2.971788e-02   \n",
       "25%    -3.154657e-01  -1.051123e-01  -5.085188e-02  -2.971788e-02   \n",
       "50%    -3.154657e-01  -1.051123e-01  -5.085188e-02  -2.971788e-02   \n",
       "75%    -3.154657e-01  -1.051123e-01  -5.085188e-02  -2.971788e-02   \n",
       "max     3.169916e+00   9.513638e+00   1.966496e+01   3.364978e+01   \n",
       "\n",
       "       6_months_late  7_months_late  8_months_late       DEFAULT  \n",
       "count   2.946600e+04   2.946600e+04   2.946600e+04  29466.000000  \n",
       "mean   -4.664973e-16  -8.970036e-16  -8.155870e-15      0.792914  \n",
       "std     1.000017e+00   1.000017e+00   1.000017e+00      0.405225  \n",
       "min    -1.932488e-02  -1.747942e-02  -2.540132e-02      0.000000  \n",
       "25%    -1.932488e-02  -1.747942e-02  -2.540132e-02      1.000000  \n",
       "50%    -1.932488e-02  -1.747942e-02  -2.540132e-02      1.000000  \n",
       "75%    -1.932488e-02  -1.747942e-02  -2.540132e-02      1.000000  \n",
       "max     5.174676e+01   5.721014e+01   3.936803e+01      1.000000  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20626, 17) (20626,)\n",
      "(8840, 17) (8840,)\n",
      "[ 4285 16341]\n"
     ]
    }
   ],
   "source": [
    "#generate a dataframe that functions as a trainingset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(credit_indep, credit_dep, test_size=0.3)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balance the data\n",
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32682, 17) (32682,)\n",
      "(8840, 17) (8840,)\n",
      "[16341 16341]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8011761535265517\n"
     ]
    }
   ],
   "source": [
    "# Do a Kfold cross validation on the training data for k = 5\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "CVscores = cross_val_score(knn, X_train, y_train, cv = 10, scoring = \"accuracy\")\n",
    "print(CVscores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a Kfold cross validation on the training data to select optimal K \n",
    "k_range = range(2,10)\n",
    "k_scores= []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    CVscores = cross_val_score(knn, X_train, y_train, cv = 10, scoring = \"accuracy\")\n",
    "    k_scores.append(CVscores.mean())\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Cross validation score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check classification accuracy using the top K that was retrieved from the Knn cross-validation\n",
    "knn = KNeighborsClassifier(n_neighbors = k_range[((k_scores.index(max(k_scores))))])\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy =\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Cohen's Kappa =\", cohen_kappa_score(y_test, y_pred))\n",
    "print(\"Recall =\", recall_score(y_test, y_pred))\n",
    "print(\"F1 score =\", f1_score(y_test, y_pred))\n",
    "print(\"ROC area under curve =\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6699714027975848\n"
     ]
    }
   ],
   "source": [
    "# Do a Kfold cross validation on the training data for a logistic regression\n",
    "\n",
    "logregression = LogisticRegression(solver='liblinear')\n",
    "CVscores = cross_val_score(logregression, X_train, y_train, cv = 10, scoring = \"accuracy\")\n",
    "print(CVscores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6765837104072399\n",
      "Cohen's Kappa = 0.24655560149186617\n",
      "Recall = 0.6867435568845223\n",
      "F1 score = 0.7713714514194323\n",
      "ROC area under curve = 0.6620289055748974\n"
     ]
    }
   ],
   "source": [
    "# Check classification accuracy using the logregression\n",
    "\n",
    "logregression.fit(X_train, y_train)\n",
    "y_pred = logregression.predict(X_test)\n",
    "print(\"Accuracy =\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Cohen's Kappa =\", cohen_kappa_score(y_test, y_pred))\n",
    "print(\"Recall =\", recall_score(y_test, y_pred))\n",
    "print(\"F1 score =\", f1_score(y_test, y_pred))\n",
    "print(\"ROC area under curve =\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train using a Support vector machine, a random forest and a logistic regression, \n",
    "\n",
    "modelSVC.fit(X_train, y_train)\n",
    "modelRF.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70864696 0.71176795 0.70313934]\n",
      "[0.77941986 0.83458785 0.83082431]\n",
      "0.711094792240377\n",
      "0.9916773759255859\n"
     ]
    }
   ],
   "source": [
    "#Print cross-validation scores \n",
    "\n",
    "print(cross_val_score(modelSVC, X_train, y_train)) \n",
    "print(cross_val_score(modelRF, X_train, y_train)) \n",
    "\n",
    "#Print model validation scores \n",
    "\n",
    "print(modelSVC.score(X_train, y_train))\n",
    "print(modelRF.score(X_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8004524886877828\n",
      "Cohen's Kappa = 0.3936968227498221\n",
      "Recall = 0.8717072476149793\n",
      "F1 score = 0.8740719588806397\n",
      "ROC area under curve = 0.6983742622224595\n",
      "[[ 954  863]\n",
      " [ 901 6122]]\n"
     ]
    }
   ],
   "source": [
    "# Check classification accuracy of using the Support Vector Machine\n",
    "y_pred = modelSVC.predict(X_test)\n",
    "print(\"Accuracy =\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Cohen's Kappa =\", cohen_kappa_score(y_test, y_pred))\n",
    "print(\"Recall =\", recall_score(y_test, y_pred))\n",
    "print(\"F1 score =\", f1_score(y_test, y_pred))\n",
    "print(\"ROC area under curve =\", roc_auc_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7406108597285068\n",
      "Cohen's Kappa = 0.2981127204214262\n",
      "Recall = 0.790830129574256\n",
      "F1 score = 0.8288933661667038\n",
      "ROC area under curve = 0.6686676789863575\n",
      "[[ 993  824]\n",
      " [1469 5554]]\n"
     ]
    }
   ],
   "source": [
    "# Check classification of accuracy using the Random forest\n",
    "y_pred = modelRF.predict(X_test)\n",
    "print(\"Accuracy =\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Cohen's Kappa =\", cohen_kappa_score(y_test, y_pred))\n",
    "print(\"Recall =\", recall_score(y_test, y_pred))\n",
    "print(\"F1 score =\", f1_score(y_test, y_pred))\n",
    "print(\"ROC area under curve =\", roc_auc_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Jeroen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(6, input_dim=6, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Jeroen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "32682/32682 [==============================] - 1s 22us/step - loss: 0.6921 - acc: 0.5408\n",
      "Epoch 2/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.6396 - acc: 0.6356\n",
      "Epoch 3/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5956 - acc: 0.6790\n",
      "Epoch 4/150\n",
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5784 - acc: 0.6931\n",
      "Epoch 5/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5733 - acc: 0.6969\n",
      "Epoch 6/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5705 - acc: 0.6966\n",
      "Epoch 7/150\n",
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5678 - acc: 0.6983\n",
      "Epoch 8/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5660 - acc: 0.6991\n",
      "Epoch 9/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5644 - acc: 0.7004\n",
      "Epoch 10/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5628 - acc: 0.7012\n",
      "Epoch 11/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5611 - acc: 0.7024\n",
      "Epoch 12/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5599 - acc: 0.7031\n",
      "Epoch 13/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5588 - acc: 0.7065\n",
      "Epoch 14/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5580 - acc: 0.7052\n",
      "Epoch 15/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5573 - acc: 0.7054\n",
      "Epoch 16/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5569 - acc: 0.7059\n",
      "Epoch 17/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5560 - acc: 0.7074\n",
      "Epoch 18/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5556 - acc: 0.7080\n",
      "Epoch 19/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5551 - acc: 0.7075\n",
      "Epoch 20/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5546 - acc: 0.7090\n",
      "Epoch 21/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5545 - acc: 0.7080\n",
      "Epoch 22/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5544 - acc: 0.7084\n",
      "Epoch 23/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5537 - acc: 0.7096\n",
      "Epoch 24/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5535 - acc: 0.7092\n",
      "Epoch 25/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5536 - acc: 0.7094\n",
      "Epoch 26/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5531 - acc: 0.7092\n",
      "Epoch 27/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5528 - acc: 0.7111\n",
      "Epoch 28/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5525 - acc: 0.7104\n",
      "Epoch 29/150\n",
      "32682/32682 [==============================] - 0s 12us/step - loss: 0.5522 - acc: 0.7114\n",
      "Epoch 30/150\n",
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5525 - acc: 0.7106\n",
      "Epoch 31/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5521 - acc: 0.7100\n",
      "Epoch 32/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5518 - acc: 0.7100\n",
      "Epoch 33/150\n",
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5519 - acc: 0.7095\n",
      "Epoch 34/150\n",
      "32682/32682 [==============================] - 0s 9us/step - loss: 0.5515 - acc: 0.7105\n",
      "Epoch 35/150\n",
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5516 - acc: 0.7108\n",
      "Epoch 36/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5513 - acc: 0.7097\n",
      "Epoch 37/150\n",
      "32682/32682 [==============================] - 0s 9us/step - loss: 0.5512 - acc: 0.7106\n",
      "Epoch 38/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5512 - acc: 0.7091\n",
      "Epoch 39/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5511 - acc: 0.7112\n",
      "Epoch 40/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5515 - acc: 0.7100\n",
      "Epoch 41/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5507 - acc: 0.7113\n",
      "Epoch 42/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5510 - acc: 0.7098\n",
      "Epoch 43/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5508 - acc: 0.7092\n",
      "Epoch 44/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5507 - acc: 0.7097\n",
      "Epoch 45/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5505 - acc: 0.7108\n",
      "Epoch 46/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5510 - acc: 0.7095\n",
      "Epoch 47/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5501 - acc: 0.7104\n",
      "Epoch 48/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5502 - acc: 0.7100\n",
      "Epoch 49/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5502 - acc: 0.7102\n",
      "Epoch 50/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5500 - acc: 0.7100\n",
      "Epoch 51/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5500 - acc: 0.7105\n",
      "Epoch 52/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5499 - acc: 0.7101\n",
      "Epoch 53/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5502 - acc: 0.7113\n",
      "Epoch 54/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5499 - acc: 0.7103\n",
      "Epoch 55/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5498 - acc: 0.7105\n",
      "Epoch 56/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5494 - acc: 0.7109\n",
      "Epoch 57/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5493 - acc: 0.7114\n",
      "Epoch 58/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5492 - acc: 0.7099\n",
      "Epoch 59/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5493 - acc: 0.7097\n",
      "Epoch 60/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5495 - acc: 0.7105\n",
      "Epoch 61/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5490 - acc: 0.7110\n",
      "Epoch 62/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5493 - acc: 0.7102\n",
      "Epoch 63/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5493 - acc: 0.7115\n",
      "Epoch 64/150\n",
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5487 - acc: 0.7113\n",
      "Epoch 65/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5485 - acc: 0.7101\n",
      "Epoch 66/150\n",
      "32682/32682 [==============================] - 0s 9us/step - loss: 0.5488 - acc: 0.7092\n",
      "Epoch 67/150\n",
      "32682/32682 [==============================] - 0s 10us/step - loss: 0.5488 - acc: 0.7119\n",
      "Epoch 68/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5485 - acc: 0.7103\n",
      "Epoch 69/150\n",
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5485 - acc: 0.7093\n",
      "Epoch 70/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5484 - acc: 0.7120\n",
      "Epoch 71/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5484 - acc: 0.7100\n",
      "Epoch 72/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5483 - acc: 0.7094\n",
      "Epoch 73/150\n",
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5482 - acc: 0.7127\n",
      "Epoch 74/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5485 - acc: 0.7091\n",
      "Epoch 75/150\n",
      "32682/32682 [==============================] - 0s 10us/step - loss: 0.5486 - acc: 0.7116\n",
      "Epoch 76/150\n",
      "32682/32682 [==============================] - 0s 9us/step - loss: 0.5482 - acc: 0.7118\n",
      "Epoch 77/150\n",
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5480 - acc: 0.7109\n",
      "Epoch 78/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5479 - acc: 0.7120\n",
      "Epoch 79/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5479 - acc: 0.7108\n",
      "Epoch 80/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5480 - acc: 0.7107\n",
      "Epoch 81/150\n",
      "32682/32682 [==============================] - 0s 11us/step - loss: 0.5479 - acc: 0.7108\n",
      "Epoch 82/150\n",
      "32682/32682 [==============================] - 0s 11us/step - loss: 0.5476 - acc: 0.7117\n",
      "Epoch 83/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5477 - acc: 0.7115\n",
      "Epoch 84/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5478 - acc: 0.7105\n",
      "Epoch 85/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5479 - acc: 0.7113\n",
      "Epoch 86/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5477 - acc: 0.7102\n",
      "Epoch 87/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5478 - acc: 0.7109\n",
      "Epoch 88/150\n",
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5477 - acc: 0.7122\n",
      "Epoch 89/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5476 - acc: 0.7117\n",
      "Epoch 90/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5479 - acc: 0.7105\n",
      "Epoch 91/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5475 - acc: 0.7111\n",
      "Epoch 92/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5477 - acc: 0.7112\n",
      "Epoch 93/150\n",
      "32682/32682 [==============================] - 0s 10us/step - loss: 0.5478 - acc: 0.7105\n",
      "Epoch 94/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5474 - acc: 0.7104\n",
      "Epoch 95/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5476 - acc: 0.7108\n",
      "Epoch 96/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5476 - acc: 0.7100\n",
      "Epoch 97/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5475 - acc: 0.7108\n",
      "Epoch 98/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5473 - acc: 0.7116\n",
      "Epoch 99/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5474 - acc: 0.7106\n",
      "Epoch 100/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5475 - acc: 0.7121\n",
      "Epoch 101/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5473 - acc: 0.7102\n",
      "Epoch 102/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5474 - acc: 0.7104\n",
      "Epoch 103/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5473 - acc: 0.7111\n",
      "Epoch 104/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5471 - acc: 0.7121\n",
      "Epoch 105/150\n",
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5477 - acc: 0.7114\n",
      "Epoch 106/150\n",
      "32682/32682 [==============================] - 0s 9us/step - loss: 0.5474 - acc: 0.7111\n",
      "Epoch 107/150\n",
      "32682/32682 [==============================] - 1s 17us/step - loss: 0.5471 - acc: 0.7111: 0s - loss: 0.5471 - acc\n",
      "Epoch 108/150\n",
      "32682/32682 [==============================] - 0s 14us/step - loss: 0.5474 - acc: 0.7108\n",
      "Epoch 109/150\n",
      "32682/32682 [==============================] - 0s 12us/step - loss: 0.5474 - acc: 0.7107\n",
      "Epoch 110/150\n",
      "32682/32682 [==============================] - 0s 11us/step - loss: 0.5472 - acc: 0.7113\n",
      "Epoch 111/150\n",
      "32682/32682 [==============================] - 0s 12us/step - loss: 0.5472 - acc: 0.7121\n",
      "Epoch 112/150\n",
      "32682/32682 [==============================] - 0s 9us/step - loss: 0.5473 - acc: 0.7104\n",
      "Epoch 113/150\n",
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5472 - acc: 0.7100\n",
      "Epoch 114/150\n",
      "32682/32682 [==============================] - 0s 11us/step - loss: 0.5474 - acc: 0.7112\n",
      "Epoch 115/150\n",
      "32682/32682 [==============================] - 0s 9us/step - loss: 0.5473 - acc: 0.7121\n",
      "Epoch 116/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5469 - acc: 0.7113\n",
      "Epoch 117/150\n",
      "32682/32682 [==============================] - 0s 10us/step - loss: 0.5473 - acc: 0.7120\n",
      "Epoch 118/150\n",
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5471 - acc: 0.7119\n",
      "Epoch 119/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5473 - acc: 0.7111\n",
      "Epoch 120/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5470 - acc: 0.7112\n",
      "Epoch 121/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5469 - acc: 0.7109\n",
      "Epoch 122/150\n",
      "32682/32682 [==============================] - 0s 10us/step - loss: 0.5470 - acc: 0.7102\n",
      "Epoch 123/150\n",
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5475 - acc: 0.7112\n",
      "Epoch 124/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5472 - acc: 0.7116\n",
      "Epoch 125/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5470 - acc: 0.7120\n",
      "Epoch 126/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5474 - acc: 0.7108\n",
      "Epoch 127/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5470 - acc: 0.7101\n",
      "Epoch 128/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5472 - acc: 0.7114\n",
      "Epoch 129/150\n",
      "32682/32682 [==============================] - 0s 13us/step - loss: 0.5469 - acc: 0.7126\n",
      "Epoch 130/150\n",
      "32682/32682 [==============================] - 0s 9us/step - loss: 0.5469 - acc: 0.7125\n",
      "Epoch 131/150\n",
      "32682/32682 [==============================] - 0s 13us/step - loss: 0.5471 - acc: 0.7110\n",
      "Epoch 132/150\n",
      "32682/32682 [==============================] - 0s 13us/step - loss: 0.5470 - acc: 0.7109\n",
      "Epoch 133/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5467 - acc: 0.7119\n",
      "Epoch 134/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5470 - acc: 0.7110\n",
      "Epoch 135/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5470 - acc: 0.7118\n",
      "Epoch 136/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5470 - acc: 0.7123\n",
      "Epoch 137/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5469 - acc: 0.7121\n",
      "Epoch 138/150\n",
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5466 - acc: 0.7116\n",
      "Epoch 139/150\n",
      "32682/32682 [==============================] - 0s 9us/step - loss: 0.5470 - acc: 0.7112\n",
      "Epoch 140/150\n",
      "32682/32682 [==============================] - 0s 5us/step - loss: 0.5470 - acc: 0.7104\n",
      "Epoch 141/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5467 - acc: 0.7120\n",
      "Epoch 142/150\n",
      "32682/32682 [==============================] - 0s 8us/step - loss: 0.5465 - acc: 0.7118\n",
      "Epoch 143/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5468 - acc: 0.7116\n",
      "Epoch 144/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5467 - acc: 0.7117\n",
      "Epoch 145/150\n",
      "32682/32682 [==============================] - 0s 7us/step - loss: 0.5466 - acc: 0.7109\n",
      "Epoch 146/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5465 - acc: 0.7111\n",
      "Epoch 147/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5466 - acc: 0.7099\n",
      "Epoch 148/150\n",
      "32682/32682 [==============================] - 0s 6us/step - loss: 0.5466 - acc: 0.7108\n",
      "Epoch 149/150\n",
      "32682/32682 [==============================] - 0s 11us/step - loss: 0.5466 - acc: 0.7092\n",
      "Epoch 150/150\n",
      "32682/32682 [==============================] - 0s 9us/step - loss: 0.5464 - acc: 0.7116\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16cd6c38a20>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run the neural network\n",
    "model.fit(X_train, y_train, epochs=150, batch_size = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7700226244343892\n",
      "Cohen's Kappa = 0.36627477021989463\n",
      "Recall = 0.8164602021927951\n",
      "F1 score = 0.8494185615880305\n",
      "ROC area under curve = 0.7034970245966727\n"
     ]
    }
   ],
   "source": [
    "#make predictions and round answers\n",
    "y_pred = model.predict(X_test)\n",
    "rounded = [round(x[0]) for x in y_pred]\n",
    "y_pred = np.array(rounded, dtype = 'int64')\n",
    "\n",
    "print(\"Accuracy =\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Cohen's Kappa =\", cohen_kappa_score(y_test, y_pred))\n",
    "print(\"Recall =\", recall_score(y_test, y_pred))\n",
    "print(\"F1 score =\", f1_score(y_test, y_pred))\n",
    "print(\"ROC area under curve =\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best results result from the SVM\n",
    "\n",
    "Accuracy = 0.8004524886877828\n",
    "\n",
    "Cohen's Kappa = 0.3936968227498221\n",
    "\n",
    "Recall = 0.8717072476149793\n",
    "\n",
    "F1 score = 0.8740719588806397\n",
    "\n",
    "ROC area under curve = 0.6983742622224595"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
