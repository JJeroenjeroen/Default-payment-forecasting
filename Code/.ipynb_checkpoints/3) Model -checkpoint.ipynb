{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import whatever will be used in this notebook\n",
    "import pylab\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import SMOTE to balance trainset \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Import from sklearn\n",
    "#Estimators:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#Set generation \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Performance metrics:\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#K-fold crossvalidation\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surpress warnings regarding the version of the pandas library which is used \n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make variable for the imported models\n",
    "modelSVC = SVC()\n",
    "modelRF = RandomForestClassifier()\n",
    "modelLR = LogisticRegression()\n",
    "modelKNN = KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the csv file and remove the extra ID column\n",
    "credit = pd.read_csv(\"C:\\\\Users\\\\Jeroen\\\\Desktop\\\\Ubiqum\\\\Data Science\\\\Excel Files\\\\credit_3.csv\", header = 0)\n",
    "credit = credit[credit.columns[1:len(credit.columns)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAYSTAT_SEP</th>\n",
       "      <th>CUR_BIL_SEP</th>\n",
       "      <th>PAID_SEP</th>\n",
       "      <th>CREDIT</th>\n",
       "      <th>CREDIT_RATIO</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DEFAULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29461</th>\n",
       "      <td>0.017741</td>\n",
       "      <td>1.849291</td>\n",
       "      <td>0.164656</td>\n",
       "      <td>0.412625</td>\n",
       "      <td>1.132625</td>\n",
       "      <td>0.387036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29462</th>\n",
       "      <td>-0.875875</td>\n",
       "      <td>-0.682263</td>\n",
       "      <td>-0.234720</td>\n",
       "      <td>-0.127385</td>\n",
       "      <td>-1.004498</td>\n",
       "      <td>0.822032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29463</th>\n",
       "      <td>3.592206</td>\n",
       "      <td>-0.656821</td>\n",
       "      <td>-0.344828</td>\n",
       "      <td>-1.053118</td>\n",
       "      <td>-0.758007</td>\n",
       "      <td>0.169538</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29464</th>\n",
       "      <td>0.911357</td>\n",
       "      <td>-0.727253</td>\n",
       "      <td>4.803964</td>\n",
       "      <td>-0.667396</td>\n",
       "      <td>1.388081</td>\n",
       "      <td>0.604534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29465</th>\n",
       "      <td>0.017741</td>\n",
       "      <td>-0.057084</td>\n",
       "      <td>-0.220274</td>\n",
       "      <td>-0.898829</td>\n",
       "      <td>1.384032</td>\n",
       "      <td>1.148279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PAYSTAT_SEP  CUR_BIL_SEP  PAID_SEP    CREDIT  CREDIT_RATIO       AGE  \\\n",
       "29461     0.017741     1.849291  0.164656  0.412625      1.132625  0.387036   \n",
       "29462    -0.875875    -0.682263 -0.234720 -0.127385     -1.004498  0.822032   \n",
       "29463     3.592206    -0.656821 -0.344828 -1.053118     -0.758007  0.169538   \n",
       "29464     0.911357    -0.727253  4.803964 -0.667396      1.388081  0.604534   \n",
       "29465     0.017741    -0.057084 -0.220274 -0.898829      1.384032  1.148279   \n",
       "\n",
       "       DEFAULT  \n",
       "29461        1  \n",
       "29462        1  \n",
       "29463        0  \n",
       "29464        0  \n",
       "29465        0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Give head of the df so it is easily visible which vars should function as independent variable\n",
    "credit.head()\n",
    "credit.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAYSTAT_SEP</th>\n",
       "      <th>CUR_BIL_SEP</th>\n",
       "      <th>PAID_SEP</th>\n",
       "      <th>CREDIT</th>\n",
       "      <th>CREDIT_RATIO</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.804974</td>\n",
       "      <td>-0.652117</td>\n",
       "      <td>-0.344828</td>\n",
       "      <td>-1.130262</td>\n",
       "      <td>-0.651099</td>\n",
       "      <td>-1.244199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.875875</td>\n",
       "      <td>-0.668758</td>\n",
       "      <td>-0.344828</td>\n",
       "      <td>-0.358818</td>\n",
       "      <td>-0.999086</td>\n",
       "      <td>-1.026701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017741</td>\n",
       "      <td>-0.309746</td>\n",
       "      <td>-0.253840</td>\n",
       "      <td>-0.590251</td>\n",
       "      <td>-0.649230</td>\n",
       "      <td>-0.156709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017741</td>\n",
       "      <td>-0.069778</td>\n",
       "      <td>-0.224950</td>\n",
       "      <td>-0.898829</td>\n",
       "      <td>1.350797</td>\n",
       "      <td>0.169538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.875875</td>\n",
       "      <td>-0.588526</td>\n",
       "      <td>-0.224950</td>\n",
       "      <td>-0.898829</td>\n",
       "      <td>-0.754215</td>\n",
       "      <td>2.344518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PAYSTAT_SEP  CUR_BIL_SEP  PAID_SEP    CREDIT  CREDIT_RATIO       AGE\n",
       "0     1.804974    -0.652117 -0.344828 -1.130262     -0.651099 -1.244199\n",
       "1    -0.875875    -0.668758 -0.344828 -0.358818     -0.999086 -1.026701\n",
       "2     0.017741    -0.309746 -0.253840 -0.590251     -0.649230 -0.156709\n",
       "3     0.017741    -0.069778 -0.224950 -0.898829      1.350797  0.169538\n",
       "4    -0.875875    -0.588526 -0.224950 -0.898829     -0.754215  2.344518"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select the features that will function as independent variables:\n",
    "credit_indep = credit.iloc[:, 0:(len(credit.columns)-1)]\n",
    "credit_indep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: DEFAULT, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select the dependent variable and turn it into a seperate vector:\n",
    "credit_dep = credit['DEFAULT']\n",
    "credit_dep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PAYSTAT_SEP</th>\n",
       "      <th>CUR_BIL_SEP</th>\n",
       "      <th>PAID_SEP</th>\n",
       "      <th>CREDIT</th>\n",
       "      <th>CREDIT_RATIO</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DEFAULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>2.946600e+04</td>\n",
       "      <td>29466.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-3.208420e-15</td>\n",
       "      <td>-2.103345e-16</td>\n",
       "      <td>2.656975e-16</td>\n",
       "      <td>-3.281235e-15</td>\n",
       "      <td>3.921537e-16</td>\n",
       "      <td>4.803280e-16</td>\n",
       "      <td>0.792914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>1.000017e+00</td>\n",
       "      <td>0.405225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.769491e+00</td>\n",
       "      <td>-2.943419e+00</td>\n",
       "      <td>-3.448283e-01</td>\n",
       "      <td>-1.207406e+00</td>\n",
       "      <td>-4.485552e+00</td>\n",
       "      <td>-1.570446e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.758749e-01</td>\n",
       "      <td>-6.490855e-01</td>\n",
       "      <td>-2.847691e-01</td>\n",
       "      <td>-8.988289e-01</td>\n",
       "      <td>-9.815463e-01</td>\n",
       "      <td>-8.092031e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.774131e-02</td>\n",
       "      <td>-3.848821e-01</td>\n",
       "      <td>-2.132614e-01</td>\n",
       "      <td>-2.045296e-01</td>\n",
       "      <td>-2.549452e-01</td>\n",
       "      <td>-1.567091e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.774131e-02</td>\n",
       "      <td>2.204590e-01</td>\n",
       "      <td>-4.252409e-02</td>\n",
       "      <td>5.669140e-01</td>\n",
       "      <td>9.783657e-01</td>\n",
       "      <td>6.045339e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.166671e+00</td>\n",
       "      <td>1.233379e+01</td>\n",
       "      <td>5.201533e+01</td>\n",
       "      <td>6.429886e+00</td>\n",
       "      <td>1.474319e+01</td>\n",
       "      <td>4.736996e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PAYSTAT_SEP   CUR_BIL_SEP      PAID_SEP        CREDIT  CREDIT_RATIO  \\\n",
       "count  2.946600e+04  2.946600e+04  2.946600e+04  2.946600e+04  2.946600e+04   \n",
       "mean  -3.208420e-15 -2.103345e-16  2.656975e-16 -3.281235e-15  3.921537e-16   \n",
       "std    1.000017e+00  1.000017e+00  1.000017e+00  1.000017e+00  1.000017e+00   \n",
       "min   -1.769491e+00 -2.943419e+00 -3.448283e-01 -1.207406e+00 -4.485552e+00   \n",
       "25%   -8.758749e-01 -6.490855e-01 -2.847691e-01 -8.988289e-01 -9.815463e-01   \n",
       "50%    1.774131e-02 -3.848821e-01 -2.132614e-01 -2.045296e-01 -2.549452e-01   \n",
       "75%    1.774131e-02  2.204590e-01 -4.252409e-02  5.669140e-01  9.783657e-01   \n",
       "max    7.166671e+00  1.233379e+01  5.201533e+01  6.429886e+00  1.474319e+01   \n",
       "\n",
       "                AGE       DEFAULT  \n",
       "count  2.946600e+04  29466.000000  \n",
       "mean   4.803280e-16      0.792914  \n",
       "std    1.000017e+00      0.405225  \n",
       "min   -1.570446e+00      0.000000  \n",
       "25%   -8.092031e-01      1.000000  \n",
       "50%   -1.567091e-01      1.000000  \n",
       "75%    6.045339e-01      1.000000  \n",
       "max    4.736996e+00      1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20626, 6) (20626,)\n",
      "(8840, 6) (8840,)\n",
      "[ 4285 16341]\n"
     ]
    }
   ],
   "source": [
    "#generate a dataframe that functions as a trainingset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(credit_indep, credit_dep, test_size=0.3)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balance the data\n",
    "smt = SMOTE()\n",
    "X_train, y_train = smt.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32682, 6) (32682,)\n",
      "(8840, 6) (8840,)\n",
      "[16341 16341]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "print(np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8021245774987928\n"
     ]
    }
   ],
   "source": [
    "# Do a Kfold cross validation on the training data for k = 5\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "CVscores = cross_val_score(knn, X_train, y_train, cv = 10, scoring = \"accuracy\")\n",
    "print(CVscores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8029802102867581, 0.8195650343054137, 0.7910476158392568, 0.8021245774987928, 0.7805220673830939, 0.7897629501532795, 0.776085626911315, 0.779574055150678, 0.7706699006958403, 0.7751988890510895, 0.7658360377153681, 0.7691712051624688, 0.7607261218974469, 0.7632353954012404, 0.7590739409864536, 0.7614302531451308, 0.755096459411811, 0.7577891068614571]\n"
     ]
    }
   ],
   "source": [
    "# Do a Kfold cross validation on the training data to select optimal K \n",
    "k_range = range(2,20)\n",
    "k_scores= []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    CVscores = cross_val_score(knn, X_train, y_train, cv = 10, scoring = \"accuracy\")\n",
    "    k_scores.append(CVscores.mean())\n",
    "print(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Cross validation score')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(k_range, k_scores)\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Cross validation score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6864253393665158\n",
      "Cohen's Kappa = 0.22078972673480923\n",
      "Recall = 0.7235563178959405\n",
      "ROC area under curve = 0.6345547316160831\n"
     ]
    }
   ],
   "source": [
    "# Check classification accuracy using the top K that was retrieved from the Knn cross-validation\n",
    "knn = KNeighborsClassifier(n_neighbors = k_range[((k_scores.index(max(k_scores))))])\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy =\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Cohen's Kappa =\", cohen_kappa_score(y_test, y_pred))\n",
    "print(\"Recall =\", recall_score(y_test, y_pred))\n",
    "print(\"ROC area under curve =\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6657193894849096\n"
     ]
    }
   ],
   "source": [
    "# Do a Kfold cross validation on the training data for a logistic regression\n",
    "\n",
    "logregression = LogisticRegression(solver='liblinear')\n",
    "CVscores = cross_val_score(logregression, X_train, y_train, cv = 10, scoring = \"accuracy\")\n",
    "print(CVscores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6630090497737556\n",
      "Cohen's Kappa = 0.23216491661519456\n",
      "Recall = 0.6692395654659805\n",
      "ROC area under curve = 0.6543052491104305\n"
     ]
    }
   ],
   "source": [
    "# Check classification accuracy using the logregression\n",
    "\n",
    "logregression.fit(X_train, y_train)\n",
    "y_pred = logregression.predict(X_test)\n",
    "print(\"Accuracy =\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Cohen's Kappa =\", cohen_kappa_score(y_test, y_pred))\n",
    "print(\"Recall =\", recall_score(y_test, y_pred))\n",
    "print(\"ROC area under curve =\", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train using a Support vector machine, a random forest and a logistic regression, \n",
    "\n",
    "modelSVC.fit(X_train, y_train)\n",
    "modelRF.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71352639 0.71425953 0.71059384]\n",
      "[0.7847324  0.83403592 0.83605205]\n",
      "0.7167949657869013\n",
      "0.9915689149560117\n"
     ]
    }
   ],
   "source": [
    "#Print cross-validation scores \n",
    "\n",
    "print(cross_val_score(modelSVC, X_train, y_train)) \n",
    "print(cross_val_score(modelRF, X_train, y_train)) \n",
    "\n",
    "#Print model validation scores \n",
    "\n",
    "print(modelSVC.score(X_train, y_train))\n",
    "print(modelRF.score(X_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7737556561085973\n",
      "Cohen's Kappa = 0.3522701027809594\n",
      "Recall = 0.8363350485991995\n",
      "ROC area under curve = 0.6863345524991659\n",
      "[[ 989  855]\n",
      " [1145 5851]]\n"
     ]
    }
   ],
   "source": [
    "# Check classification accuracy of using the Support Vector Machine\n",
    "y_pred = modelSVC.predict(X_test)\n",
    "print(\"Accuracy =\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Cohen's Kappa =\", cohen_kappa_score(y_test, y_pred))\n",
    "print(\"Recall =\", recall_score(y_test, y_pred))\n",
    "print(\"ROC area under curve =\", roc_auc_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7476244343891403\n",
      "Cohen's Kappa = 0.30412081584170936\n",
      "Recall = 0.8053173241852487\n",
      "ROC area under curve = 0.667029594847505\n",
      "[[ 975  869]\n",
      " [1362 5634]]\n"
     ]
    }
   ],
   "source": [
    "# Check classification of accuracy using the Random forest\n",
    "y_pred = modelRF.predict(X_test)\n",
    "print(\"Accuracy =\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Cohen's Kappa =\", cohen_kappa_score(y_test, y_pred))\n",
    "print(\"Recall =\", recall_score(y_test, y_pred))\n",
    "print(\"ROC area under curve =\", roc_auc_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(6, input_dim=6, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Users\\Jeroen\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "32682/32682 [==============================] - 4s 121us/step - loss: 0.5895 - acc: 0.6798\n",
      "Epoch 2/150\n",
      "32682/32682 [==============================] - 4s 113us/step - loss: 0.5700 - acc: 0.6981\n",
      "Epoch 3/150\n",
      "32682/32682 [==============================] - 4s 122us/step - loss: 0.5650 - acc: 0.7040\n",
      "Epoch 4/150\n",
      "32682/32682 [==============================] - 4s 109us/step - loss: 0.5621 - acc: 0.7067\n",
      "Epoch 5/150\n",
      "32682/32682 [==============================] - 4s 110us/step - loss: 0.5596 - acc: 0.7077\n",
      "Epoch 6/150\n",
      "32682/32682 [==============================] - 4s 109us/step - loss: 0.5578 - acc: 0.7104\n",
      "Epoch 7/150\n",
      "32682/32682 [==============================] - 4s 115us/step - loss: 0.5571 - acc: 0.7062\n",
      "Epoch 8/150\n",
      "32682/32682 [==============================] - 4s 118us/step - loss: 0.5563 - acc: 0.7076\n",
      "Epoch 9/150\n",
      "32682/32682 [==============================] - 4s 110us/step - loss: 0.5556 - acc: 0.7079\n",
      "Epoch 10/150\n",
      "32682/32682 [==============================] - 4s 113us/step - loss: 0.5550 - acc: 0.7087\n",
      "Epoch 11/150\n",
      "32682/32682 [==============================] - 4s 110us/step - loss: 0.5545 - acc: 0.7099\n",
      "Epoch 12/150\n",
      "32682/32682 [==============================] - 4s 125us/step - loss: 0.5539 - acc: 0.7105\n",
      "Epoch 13/150\n",
      "32682/32682 [==============================] - 4s 120us/step - loss: 0.5535 - acc: 0.7102\n",
      "Epoch 14/150\n",
      "32682/32682 [==============================] - 4s 113us/step - loss: 0.5525 - acc: 0.7116\n",
      "Epoch 15/150\n",
      "32682/32682 [==============================] - 4s 117us/step - loss: 0.5524 - acc: 0.7106\n",
      "Epoch 16/150\n",
      "32682/32682 [==============================] - 5s 138us/step - loss: 0.5517 - acc: 0.7111\n",
      "Epoch 17/150\n",
      "32682/32682 [==============================] - 4s 116us/step - loss: 0.5517 - acc: 0.7105\n",
      "Epoch 18/150\n",
      "32682/32682 [==============================] - 4s 116us/step - loss: 0.5515 - acc: 0.7106\n",
      "Epoch 19/150\n",
      "32682/32682 [==============================] - 4s 115us/step - loss: 0.5509 - acc: 0.7124\n",
      "Epoch 20/150\n",
      "32682/32682 [==============================] - 4s 130us/step - loss: 0.5506 - acc: 0.7116\n",
      "Epoch 21/150\n",
      "32682/32682 [==============================] - 4s 118us/step - loss: 0.5501 - acc: 0.7116\n",
      "Epoch 22/150\n",
      "32682/32682 [==============================] - 4s 121us/step - loss: 0.5497 - acc: 0.7113\n",
      "Epoch 23/150\n",
      "32682/32682 [==============================] - 4s 126us/step - loss: 0.5497 - acc: 0.7115\n",
      "Epoch 24/150\n",
      "32682/32682 [==============================] - 4s 132us/step - loss: 0.5490 - acc: 0.7117\n",
      "Epoch 25/150\n",
      "32682/32682 [==============================] - 4s 122us/step - loss: 0.5489 - acc: 0.7133\n",
      "Epoch 26/150\n",
      "32682/32682 [==============================] - 4s 133us/step - loss: 0.5482 - acc: 0.7126\n",
      "Epoch 27/150\n",
      "32682/32682 [==============================] - 4s 118us/step - loss: 0.5483 - acc: 0.7138\n",
      "Epoch 28/150\n",
      "32682/32682 [==============================] - 5s 148us/step - loss: 0.5484 - acc: 0.7130\n",
      "Epoch 29/150\n",
      "32682/32682 [==============================] - 6s 196us/step - loss: 0.5479 - acc: 0.7134\n",
      "Epoch 30/150\n",
      "32682/32682 [==============================] - 6s 196us/step - loss: 0.5481 - acc: 0.7110\n",
      "Epoch 31/150\n",
      "32682/32682 [==============================] - 6s 187us/step - loss: 0.5478 - acc: 0.7132\n",
      "Epoch 32/150\n",
      "32682/32682 [==============================] - 4s 128us/step - loss: 0.5477 - acc: 0.7124\n",
      "Epoch 33/150\n",
      "32682/32682 [==============================] - 4s 126us/step - loss: 0.5474 - acc: 0.7132\n",
      "Epoch 34/150\n",
      "32682/32682 [==============================] - 4s 130us/step - loss: 0.5476 - acc: 0.7140\n",
      "Epoch 35/150\n",
      "32682/32682 [==============================] - 4s 119us/step - loss: 0.5476 - acc: 0.7130\n",
      "Epoch 36/150\n",
      "32682/32682 [==============================] - 5s 165us/step - loss: 0.5474 - acc: 0.7129\n",
      "Epoch 37/150\n",
      "32682/32682 [==============================] - 6s 191us/step - loss: 0.5474 - acc: 0.7136\n",
      "Epoch 38/150\n",
      "32682/32682 [==============================] - 4s 120us/step - loss: 0.5474 - acc: 0.7125\n",
      "Epoch 39/150\n",
      "32682/32682 [==============================] - 4s 113us/step - loss: 0.5471 - acc: 0.7148\n",
      "Epoch 40/150\n",
      "32682/32682 [==============================] - 4s 128us/step - loss: 0.5475 - acc: 0.7118\n",
      "Epoch 41/150\n",
      "32682/32682 [==============================] - 5s 139us/step - loss: 0.5472 - acc: 0.7124\n",
      "Epoch 42/150\n",
      "32682/32682 [==============================] - 4s 128us/step - loss: 0.5469 - acc: 0.7120\n",
      "Epoch 43/150\n",
      "32682/32682 [==============================] - 4s 127us/step - loss: 0.5470 - acc: 0.7121\n",
      "Epoch 44/150\n",
      "32682/32682 [==============================] - 5s 152us/step - loss: 0.5470 - acc: 0.7125\n",
      "Epoch 45/150\n",
      "32682/32682 [==============================] - 4s 135us/step - loss: 0.5466 - acc: 0.7135\n",
      "Epoch 46/150\n",
      "32682/32682 [==============================] - 4s 122us/step - loss: 0.5468 - acc: 0.7143\n",
      "Epoch 47/150\n",
      "32682/32682 [==============================] - 4s 117us/step - loss: 0.5467 - acc: 0.7136\n",
      "Epoch 48/150\n",
      "32682/32682 [==============================] - 5s 143us/step - loss: 0.5465 - acc: 0.7129\n",
      "Epoch 49/150\n",
      "32682/32682 [==============================] - 4s 138us/step - loss: 0.5463 - acc: 0.7139\n",
      "Epoch 50/150\n",
      "32682/32682 [==============================] - 5s 154us/step - loss: 0.5461 - acc: 0.7150\n",
      "Epoch 51/150\n",
      "32682/32682 [==============================] - 7s 203us/step - loss: 0.5465 - acc: 0.7146\n",
      "Epoch 52/150\n",
      "32682/32682 [==============================] - 9s 264us/step - loss: 0.5462 - acc: 0.7146\n",
      "Epoch 53/150\n",
      "32682/32682 [==============================] - 8s 258us/step - loss: 0.5462 - acc: 0.7129\n",
      "Epoch 54/150\n",
      "32682/32682 [==============================] - 5s 145us/step - loss: 0.5462 - acc: 0.7153\n",
      "Epoch 55/150\n",
      "32682/32682 [==============================] - 3s 96us/step - loss: 0.5462 - acc: 0.7121\n",
      "Epoch 56/150\n",
      "32682/32682 [==============================] - 3s 104us/step - loss: 0.5460 - acc: 0.7142\n",
      "Epoch 57/150\n",
      "32682/32682 [==============================] - 4s 132us/step - loss: 0.5460 - acc: 0.7140\n",
      "Epoch 58/150\n",
      "32682/32682 [==============================] - 5s 160us/step - loss: 0.5459 - acc: 0.7144\n",
      "Epoch 59/150\n",
      "32682/32682 [==============================] - 5s 140us/step - loss: 0.5457 - acc: 0.7138\n",
      "Epoch 60/150\n",
      "32682/32682 [==============================] - 5s 156us/step - loss: 0.5455 - acc: 0.7154\n",
      "Epoch 61/150\n",
      "32682/32682 [==============================] - 5s 158us/step - loss: 0.5457 - acc: 0.7138\n",
      "Epoch 62/150\n",
      "32682/32682 [==============================] - 5s 152us/step - loss: 0.5457 - acc: 0.7136\n",
      "Epoch 63/150\n",
      "32682/32682 [==============================] - 5s 143us/step - loss: 0.5459 - acc: 0.7123\n",
      "Epoch 64/150\n",
      "32682/32682 [==============================] - 5s 143us/step - loss: 0.5454 - acc: 0.7153\n",
      "Epoch 65/150\n",
      "32682/32682 [==============================] - 4s 134us/step - loss: 0.5458 - acc: 0.7140\n",
      "Epoch 66/150\n",
      "32682/32682 [==============================] - 4s 127us/step - loss: 0.5456 - acc: 0.7144\n",
      "Epoch 67/150\n",
      "32682/32682 [==============================] - 3s 107us/step - loss: 0.5455 - acc: 0.7164\n",
      "Epoch 68/150\n",
      "32682/32682 [==============================] - 3s 95us/step - loss: 0.5460 - acc: 0.7146\n",
      "Epoch 69/150\n",
      "32682/32682 [==============================] - 3s 90us/step - loss: 0.5454 - acc: 0.7126\n",
      "Epoch 70/150\n",
      "32682/32682 [==============================] - 3s 88us/step - loss: 0.5453 - acc: 0.7121\n",
      "Epoch 71/150\n",
      "32682/32682 [==============================] - 4s 108us/step - loss: 0.5455 - acc: 0.7156\n",
      "Epoch 72/150\n",
      "32682/32682 [==============================] - 3s 96us/step - loss: 0.5454 - acc: 0.7154\n",
      "Epoch 73/150\n",
      "32682/32682 [==============================] - 4s 117us/step - loss: 0.5455 - acc: 0.7144\n",
      "Epoch 74/150\n",
      "32682/32682 [==============================] - 3s 89us/step - loss: 0.5451 - acc: 0.7158\n",
      "Epoch 75/150\n",
      "32682/32682 [==============================] - 3s 102us/step - loss: 0.5450 - acc: 0.7139\n",
      "Epoch 76/150\n",
      "32682/32682 [==============================] - 3s 97us/step - loss: 0.5452 - acc: 0.7129\n",
      "Epoch 77/150\n",
      "32682/32682 [==============================] - 3s 106us/step - loss: 0.5453 - acc: 0.7150\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32682/32682 [==============================] - 5s 142us/step - loss: 0.5452 - acc: 0.7132\n",
      "Epoch 79/150\n",
      "32682/32682 [==============================] - 4s 125us/step - loss: 0.5453 - acc: 0.7160\n",
      "Epoch 80/150\n",
      "32682/32682 [==============================] - 4s 108us/step - loss: 0.5447 - acc: 0.7154\n",
      "Epoch 81/150\n",
      "32682/32682 [==============================] - 4s 110us/step - loss: 0.5450 - acc: 0.7140\n",
      "Epoch 82/150\n",
      "32682/32682 [==============================] - 4s 133us/step - loss: 0.5450 - acc: 0.7140\n",
      "Epoch 83/150\n",
      "32682/32682 [==============================] - 4s 121us/step - loss: 0.5451 - acc: 0.7151\n",
      "Epoch 84/150\n",
      "32682/32682 [==============================] - 5s 151us/step - loss: 0.5447 - acc: 0.7149\n",
      "Epoch 85/150\n",
      "32682/32682 [==============================] - 4s 131us/step - loss: 0.5449 - acc: 0.7155\n",
      "Epoch 86/150\n",
      "32682/32682 [==============================] - 4s 124us/step - loss: 0.5446 - acc: 0.7146\n",
      "Epoch 87/150\n",
      "32682/32682 [==============================] - 5s 144us/step - loss: 0.5446 - acc: 0.7148\n",
      "Epoch 88/150\n",
      "32682/32682 [==============================] - 4s 124us/step - loss: 0.5448 - acc: 0.7149\n",
      "Epoch 89/150\n",
      "32682/32682 [==============================] - 3s 98us/step - loss: 0.5447 - acc: 0.7150\n",
      "Epoch 90/150\n",
      "32682/32682 [==============================] - ETA: 0s - loss: 0.5446 - acc: 0.713 - 4s 118us/step - loss: 0.5445 - acc: 0.7138\n",
      "Epoch 91/150\n",
      "32682/32682 [==============================] - 3s 95us/step - loss: 0.5449 - acc: 0.7146\n",
      "Epoch 92/150\n",
      "32682/32682 [==============================] - 4s 118us/step - loss: 0.5448 - acc: 0.7153\n",
      "Epoch 93/150\n",
      "32682/32682 [==============================] - 5s 161us/step - loss: 0.5449 - acc: 0.7130\n",
      "Epoch 94/150\n",
      "32682/32682 [==============================] - 3s 102us/step - loss: 0.5445 - acc: 0.7154\n",
      "Epoch 95/150\n",
      "32682/32682 [==============================] - 3s 90us/step - loss: 0.5445 - acc: 0.7159\n",
      "Epoch 96/150\n",
      "32682/32682 [==============================] - 3s 93us/step - loss: 0.5441 - acc: 0.7153\n",
      "Epoch 97/150\n",
      "32682/32682 [==============================] - 3s 90us/step - loss: 0.5443 - acc: 0.7130\n",
      "Epoch 98/150\n",
      "32682/32682 [==============================] - 3s 97us/step - loss: 0.5446 - acc: 0.7158\n",
      "Epoch 99/150\n",
      "32682/32682 [==============================] - 3s 88us/step - loss: 0.5441 - acc: 0.7155\n",
      "Epoch 100/150\n",
      "32682/32682 [==============================] - 3s 88us/step - loss: 0.5446 - acc: 0.7157\n",
      "Epoch 101/150\n",
      "32682/32682 [==============================] - 3s 91us/step - loss: 0.5444 - acc: 0.7156\n",
      "Epoch 102/150\n",
      "32682/32682 [==============================] - 3s 88us/step - loss: 0.5444 - acc: 0.7145\n",
      "Epoch 103/150\n",
      "32682/32682 [==============================] - 3s 99us/step - loss: 0.5444 - acc: 0.7163\n",
      "Epoch 104/150\n",
      "32682/32682 [==============================] - 4s 115us/step - loss: 0.5444 - acc: 0.7159\n",
      "Epoch 105/150\n",
      "32682/32682 [==============================] - 5s 149us/step - loss: 0.5440 - acc: 0.7152\n",
      "Epoch 106/150\n",
      "32682/32682 [==============================] - 3s 90us/step - loss: 0.5446 - acc: 0.7140\n",
      "Epoch 107/150\n",
      "32682/32682 [==============================] - 3s 88us/step - loss: 0.5444 - acc: 0.7160\n",
      "Epoch 108/150\n",
      "32682/32682 [==============================] - 3s 107us/step - loss: 0.5443 - acc: 0.7166\n",
      "Epoch 109/150\n",
      "32682/32682 [==============================] - 3s 104us/step - loss: 0.5443 - acc: 0.7148\n",
      "Epoch 110/150\n",
      "32682/32682 [==============================] - 3s 93us/step - loss: 0.5439 - acc: 0.7160\n",
      "Epoch 111/150\n",
      "32682/32682 [==============================] - 3s 91us/step - loss: 0.5440 - acc: 0.7152\n",
      "Epoch 112/150\n",
      "32682/32682 [==============================] - 3s 89us/step - loss: 0.5438 - acc: 0.7155\n",
      "Epoch 113/150\n",
      "32682/32682 [==============================] - 3s 104us/step - loss: 0.5441 - acc: 0.7147\n",
      "Epoch 114/150\n",
      "32682/32682 [==============================] - 3s 91us/step - loss: 0.5440 - acc: 0.7171\n",
      "Epoch 115/150\n",
      "32682/32682 [==============================] - 3s 93us/step - loss: 0.5445 - acc: 0.7157\n",
      "Epoch 116/150\n",
      "32682/32682 [==============================] - 3s 88us/step - loss: 0.5442 - acc: 0.7157\n",
      "Epoch 117/150\n",
      "32682/32682 [==============================] - 3s 90us/step - loss: 0.5445 - acc: 0.7153\n",
      "Epoch 118/150\n",
      "32682/32682 [==============================] - 4s 126us/step - loss: 0.5440 - acc: 0.7163\n",
      "Epoch 119/150\n",
      "32682/32682 [==============================] - 4s 137us/step - loss: 0.5441 - acc: 0.7150\n",
      "Epoch 120/150\n",
      "32682/32682 [==============================] - 4s 123us/step - loss: 0.5444 - acc: 0.7151\n",
      "Epoch 121/150\n",
      "32682/32682 [==============================] - 4s 129us/step - loss: 0.5439 - acc: 0.7161\n",
      "Epoch 122/150\n",
      "32682/32682 [==============================] - 5s 157us/step - loss: 0.5441 - acc: 0.7151\n",
      "Epoch 123/150\n",
      "32682/32682 [==============================] - 5s 139us/step - loss: 0.5440 - acc: 0.7170\n",
      "Epoch 124/150\n",
      "32682/32682 [==============================] - 4s 132us/step - loss: 0.5442 - acc: 0.7164\n",
      "Epoch 125/150\n",
      "32682/32682 [==============================] - 5s 139us/step - loss: 0.5441 - acc: 0.7161\n",
      "Epoch 126/150\n",
      "32682/32682 [==============================] - 4s 128us/step - loss: 0.5439 - acc: 0.7158\n",
      "Epoch 127/150\n",
      "32682/32682 [==============================] - 4s 126us/step - loss: 0.5442 - acc: 0.7160\n",
      "Epoch 128/150\n",
      "32682/32682 [==============================] - 4s 119us/step - loss: 0.5438 - acc: 0.7158\n",
      "Epoch 129/150\n",
      "32682/32682 [==============================] - 4s 125us/step - loss: 0.5441 - acc: 0.7159\n",
      "Epoch 130/150\n",
      "32682/32682 [==============================] - 5s 139us/step - loss: 0.5443 - acc: 0.7163\n",
      "Epoch 131/150\n",
      "32682/32682 [==============================] - 4s 128us/step - loss: 0.5436 - acc: 0.7175\n",
      "Epoch 132/150\n",
      "32682/32682 [==============================] - 3s 92us/step - loss: 0.5437 - acc: 0.7156\n",
      "Epoch 133/150\n",
      "32682/32682 [==============================] - 4s 111us/step - loss: 0.5438 - acc: 0.7166\n",
      "Epoch 134/150\n",
      "32682/32682 [==============================] - 3s 93us/step - loss: 0.5439 - acc: 0.7168\n",
      "Epoch 135/150\n",
      "32682/32682 [==============================] - 4s 135us/step - loss: 0.5437 - acc: 0.7148\n",
      "Epoch 136/150\n",
      "32682/32682 [==============================] - 4s 112us/step - loss: 0.5437 - acc: 0.7164\n",
      "Epoch 137/150\n",
      "32682/32682 [==============================] - 3s 93us/step - loss: 0.5439 - acc: 0.7157\n",
      "Epoch 138/150\n",
      "32682/32682 [==============================] - 4s 129us/step - loss: 0.5439 - acc: 0.7169\n",
      "Epoch 139/150\n",
      "32682/32682 [==============================] - 5s 138us/step - loss: 0.5438 - acc: 0.7146\n",
      "Epoch 140/150\n",
      "32682/32682 [==============================] - 4s 131us/step - loss: 0.5431 - acc: 0.7175\n",
      "Epoch 141/150\n",
      "32682/32682 [==============================] - 4s 136us/step - loss: 0.5435 - acc: 0.7155\n",
      "Epoch 142/150\n",
      "32682/32682 [==============================] - 5s 143us/step - loss: 0.5439 - acc: 0.7165\n",
      "Epoch 143/150\n",
      "32682/32682 [==============================] - 5s 160us/step - loss: 0.5439 - acc: 0.7141\n",
      "Epoch 144/150\n",
      "32682/32682 [==============================] - 4s 116us/step - loss: 0.5438 - acc: 0.7161\n",
      "Epoch 145/150\n",
      "32682/32682 [==============================] - 4s 113us/step - loss: 0.5440 - acc: 0.7151\n",
      "Epoch 146/150\n",
      "32682/32682 [==============================] - 3s 102us/step - loss: 0.5433 - acc: 0.7170\n",
      "Epoch 147/150\n",
      "32682/32682 [==============================] - 5s 148us/step - loss: 0.5438 - acc: 0.7148\n",
      "Epoch 148/150\n",
      "32682/32682 [==============================] - 4s 123us/step - loss: 0.5439 - acc: 0.7165\n",
      "Epoch 149/150\n",
      "32682/32682 [==============================] - 3s 98us/step - loss: 0.5435 - acc: 0.7148\n",
      "Epoch 150/150\n",
      "32682/32682 [==============================] - 3s 94us/step - loss: 0.5439 - acc: 0.7135\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159882d6438>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run the neural network\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.7368778280542987\n",
      "Cohen's Kappa = 0.33779048058518113\n",
      "Recall = 0.7587925388010821\n",
      "ROC area under curve = 0.7054832259222801\n"
     ]
    }
   ],
   "source": [
    "#make predictions and round answers\n",
    "y_pred = model.predict(X_test)\n",
    "rounded = [round(x[0]) for x in y_pred]\n",
    "y_pred = np.array(rounded, dtype = 'int64')\n",
    "\n",
    "print(\"Accuracy =\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Cohen's Kappa =\", cohen_kappa_score(y_test, y_pred))\n",
    "print(\"Recall =\", recall_score(y_test, y_pred))\n",
    "print(\"ROC area under curve =\", roc_auc_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
